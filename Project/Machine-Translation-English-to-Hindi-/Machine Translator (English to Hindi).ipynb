{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jump.\tउछलो.\n",
      "['Help!', 'बचाओ!']\n"
     ]
    }
   ],
   "source": [
    "# Assign the data path.\n",
    "data_path = \"hin.txt\"\n",
    "\n",
    "# Read in the data.\n",
    "lines = io.open(data_path, encoding = \"utf-8\").read().split(\"\\n\")\n",
    "lines  = lines[:-1]\n",
    "print(lines[1])\n",
    "# Split the data into input and target sequences.\n",
    "lines = [line.split(\"\\t\") for line in lines]\n",
    "print(lines[0])\n",
    "# We define the starting signal to be \"\\t\" and the\n",
    "# ending signal to be \"\\n\". These signals tell the\n",
    "# model that when it sees \"\\t\" it should start\n",
    "# producing its translation and produce \"\\n\" when\n",
    "# it wants to end its translation. Let us add\n",
    "# \"\\t\" to the start and \"\\n\" to the end \n",
    "# of all input and output sentences.\n",
    "lines = [(\"\\t\" + line[0] + \"\\n\", \"\\t\" + line[1] + \"\\n\") for\n",
    "            line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tबचाओ!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (lines[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure out the Best Lengths of Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sentence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the input and output lengths.\n",
    "input_lengths = np.array([len(line[0]) for line in lines])\n",
    "output_lengths = np.array([len(line[1]) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input samples= 2869\n",
      "output Sampls= 2869\n"
     ]
    }
   ],
   "source": [
    "print(\"Input samples=\", len(input_lengths))\n",
    "print(\"output Sampls=\", len(output_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.0, 80.0, 0.0, 120.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(input_lengths)\n",
    "plt.axis([75,80, 0 , 120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.0, 89.0, 0.0, 20.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(output_lengths)\n",
    "plt.axis([85,89,0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = 78\n",
    "hindi = 87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = []\n",
    "for i in range(len(input_lengths)):\n",
    "    if(input_lengths[i]<75 and output_lengths[i]<85):\n",
    "        line1 = line1 + [lines[i]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2856\n"
     ]
    }
   ],
   "source": [
    "print(len(line1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotted the histogram of the length of the input sentences and choose the length that makes the most sense. \n",
    "\n",
    "The reason we don't want sentences that are too long is because the computation becomes trickier for longer sentences and the performance also degrades. However we also want as many sentences in our dataset as possible.\n",
    "\n",
    "Thus it is important to choose the right length and discard sentences longer than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same for the lengths of the output sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 2869  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [(line[0]) for line in line1]\n",
    "target_texts = [(line[1]) for line in line1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_text in input_texts:\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "\n",
    "for target_text in target_texts:\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(input_characters))\n",
    "print(len(target_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2856\n",
      "Number of unique input tokens: 72\n",
      "Number of unique output tokens: 92\n",
      "Max sequence length for inputs: 74\n",
      "Max sequence length for outputs: 82\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            \n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2284 samples, validate on 572 samples\n",
      "Epoch 1/100\n",
      "2284/2284 [==============================] - 47s 21ms/step - loss: 1.2284 - val_loss: 1.9019\n",
      "Epoch 2/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 1.1319 - val_loss: 1.8678\n",
      "Epoch 3/100\n",
      "2284/2284 [==============================] - 38s 17ms/step - loss: 1.1290 - val_loss: 1.7525\n",
      "Epoch 4/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 1.0081 - val_loss: 1.6189\n",
      "Epoch 5/100\n",
      "2284/2284 [==============================] - 49s 21ms/step - loss: 0.9196 - val_loss: 1.4952\n",
      "Epoch 6/100\n",
      "2284/2284 [==============================] - 55s 24ms/step - loss: 0.8673 - val_loss: 1.4573\n",
      "Epoch 7/100\n",
      "2284/2284 [==============================] - 67s 29ms/step - loss: 0.8244 - val_loss: 1.4195\n",
      "Epoch 8/100\n",
      "2284/2284 [==============================] - 43s 19ms/step - loss: 0.8034 - val_loss: 1.3386\n",
      "Epoch 9/100\n",
      "2284/2284 [==============================] - 38s 17ms/step - loss: 0.7667 - val_loss: 1.2996\n",
      "Epoch 10/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.7433 - val_loss: 1.2884\n",
      "Epoch 11/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.7257 - val_loss: 1.2818\n",
      "Epoch 12/100\n",
      "2284/2284 [==============================] - 40s 18ms/step - loss: 0.7095 - val_loss: 1.2554\n",
      "Epoch 13/100\n",
      "2284/2284 [==============================] - 41s 18ms/step - loss: 0.6963 - val_loss: 1.2182\n",
      "Epoch 14/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.6843 - val_loss: 1.2134\n",
      "Epoch 15/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.6720 - val_loss: 1.2021\n",
      "Epoch 16/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.6615 - val_loss: 1.1827\n",
      "Epoch 17/100\n",
      "2284/2284 [==============================] - 38s 17ms/step - loss: 0.6508 - val_loss: 1.1660\n",
      "Epoch 18/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.6417 - val_loss: 1.1597\n",
      "Epoch 19/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.6320 - val_loss: 1.1551\n",
      "Epoch 20/100\n",
      "2284/2284 [==============================] - 38s 17ms/step - loss: 0.6230 - val_loss: 1.1555\n",
      "Epoch 21/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.6141 - val_loss: 1.1353\n",
      "Epoch 22/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.6059 - val_loss: 1.1373\n",
      "Epoch 23/100\n",
      "2284/2284 [==============================] - 38s 17ms/step - loss: 0.5968 - val_loss: 1.1329\n",
      "Epoch 24/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5930 - val_loss: 1.1167\n",
      "Epoch 25/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5816 - val_loss: 1.1160\n",
      "Epoch 26/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5730 - val_loss: 1.1051\n",
      "Epoch 27/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5656 - val_loss: 1.1151\n",
      "Epoch 28/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5586 - val_loss: 1.1136\n",
      "Epoch 29/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5504 - val_loss: 1.1031\n",
      "Epoch 30/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5437 - val_loss: 1.1035\n",
      "Epoch 31/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5375 - val_loss: 1.1055\n",
      "Epoch 32/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.5284 - val_loss: 1.1164\n",
      "Epoch 33/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5212 - val_loss: 1.0861\n",
      "Epoch 34/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.5144 - val_loss: 1.1035\n",
      "Epoch 35/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5075 - val_loss: 1.0951\n",
      "Epoch 36/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.5003 - val_loss: 1.1088\n",
      "Epoch 37/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.4930 - val_loss: 1.1103\n",
      "Epoch 38/100\n",
      "2284/2284 [==============================] - 41s 18ms/step - loss: 0.4866 - val_loss: 1.1073\n",
      "Epoch 39/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.4781 - val_loss: 1.1226\n",
      "Epoch 40/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.4719 - val_loss: 1.1174\n",
      "Epoch 41/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.4643 - val_loss: 1.0965\n",
      "Epoch 42/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.4575 - val_loss: 1.1181\n",
      "Epoch 43/100\n",
      "2284/2284 [==============================] - 43s 19ms/step - loss: 0.4502 - val_loss: 1.1148\n",
      "Epoch 44/100\n",
      "2284/2284 [==============================] - 42s 18ms/step - loss: 0.4444 - val_loss: 1.1203\n",
      "Epoch 45/100\n",
      "2284/2284 [==============================] - 42s 18ms/step - loss: 0.4363 - val_loss: 1.1347\n",
      "Epoch 46/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.4293 - val_loss: 1.1245\n",
      "Epoch 47/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.4232 - val_loss: 1.1318\n",
      "Epoch 48/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.4151 - val_loss: 1.1537\n",
      "Epoch 49/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.4082 - val_loss: 1.1611\n",
      "Epoch 50/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.4015 - val_loss: 1.1756\n",
      "Epoch 51/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.3955 - val_loss: 1.1639\n",
      "Epoch 52/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.3884 - val_loss: 1.1753\n",
      "Epoch 53/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.3815 - val_loss: 1.1745\n",
      "Epoch 54/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.3749 - val_loss: 1.1989\n",
      "Epoch 55/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.3691 - val_loss: 1.2061\n",
      "Epoch 56/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.3620 - val_loss: 1.2149\n",
      "Epoch 57/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.3568 - val_loss: 1.2294\n",
      "Epoch 58/100\n",
      "2284/2284 [==============================] - 41s 18ms/step - loss: 0.3508 - val_loss: 1.2336\n",
      "Epoch 59/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.3439 - val_loss: 1.2423\n",
      "Epoch 60/100\n",
      "2284/2284 [==============================] - 40s 18ms/step - loss: 0.3381 - val_loss: 1.2559\n",
      "Epoch 61/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.3328 - val_loss: 1.2654\n",
      "Epoch 62/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.3259 - val_loss: 1.2731\n",
      "Epoch 63/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.3209 - val_loss: 1.2778\n",
      "Epoch 64/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.3162 - val_loss: 1.2945\n",
      "Epoch 65/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.3098 - val_loss: 1.3212\n",
      "Epoch 66/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.3045 - val_loss: 1.3328\n",
      "Epoch 67/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.2995 - val_loss: 1.3223\n",
      "Epoch 68/100\n",
      "2284/2284 [==============================] - 41s 18ms/step - loss: 0.2952 - val_loss: 1.3382\n",
      "Epoch 69/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2897 - val_loss: 1.3387\n",
      "Epoch 70/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2846 - val_loss: 1.3612\n",
      "Epoch 71/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2795 - val_loss: 1.3779\n",
      "Epoch 72/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2760 - val_loss: 1.3848\n",
      "Epoch 73/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2704 - val_loss: 1.4041\n",
      "Epoch 74/100\n",
      "2284/2284 [==============================] - 41s 18ms/step - loss: 0.2661 - val_loss: 1.4294\n",
      "Epoch 75/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.2624 - val_loss: 1.4246\n",
      "Epoch 76/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.2575 - val_loss: 1.4271\n",
      "Epoch 77/100\n",
      "2284/2284 [==============================] - 41s 18ms/step - loss: 0.2540 - val_loss: 1.4349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "2284/2284 [==============================] - 43s 19ms/step - loss: 0.2502 - val_loss: 1.4519\n",
      "Epoch 79/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2461 - val_loss: 1.4566\n",
      "Epoch 80/100\n",
      "2284/2284 [==============================] - 40s 18ms/step - loss: 0.2429 - val_loss: 1.4803\n",
      "Epoch 81/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2392 - val_loss: 1.4836\n",
      "Epoch 82/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.2354 - val_loss: 1.4905\n",
      "Epoch 83/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.2313 - val_loss: 1.4987\n",
      "Epoch 84/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2274 - val_loss: 1.5370\n",
      "Epoch 85/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2263 - val_loss: 1.5244\n",
      "Epoch 86/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2218 - val_loss: 1.5377\n",
      "Epoch 87/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2180 - val_loss: 1.5597\n",
      "Epoch 88/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2160 - val_loss: 1.5730\n",
      "Epoch 89/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.2129 - val_loss: 1.5719\n",
      "Epoch 90/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2097 - val_loss: 1.5841\n",
      "Epoch 91/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.2068 - val_loss: 1.5946\n",
      "Epoch 92/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.2042 - val_loss: 1.6083\n",
      "Epoch 93/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.2019 - val_loss: 1.6205\n",
      "Epoch 94/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.1988 - val_loss: 1.6499\n",
      "Epoch 95/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.1956 - val_loss: 1.6399\n",
      "Epoch 96/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.1932 - val_loss: 1.6503\n",
      "Epoch 97/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.1916 - val_loss: 1.6438\n",
      "Epoch 98/100\n",
      "2284/2284 [==============================] - 40s 17ms/step - loss: 0.1885 - val_loss: 1.6832\n",
      "Epoch 99/100\n",
      "2284/2284 [==============================] - 39s 17ms/step - loss: 0.1869 - val_loss: 1.6895\n",
      "Epoch 100/100\n",
      "2284/2284 [==============================] - 40s 18ms/step - loss: 0.1849 - val_loss: 1.6946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23485ec9c48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3ad4c1811ba8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m's2s.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "\tHelp!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tJump.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tJump.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tJump.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHello!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHello!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tCheers!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tCheers!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tGot it?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm OK.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tAwesome!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tCome in.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tGet out!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tGo away!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tGoodbye!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tPerfect!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tPerfect!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWelcome.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWelcome.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHave fun.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHave fun.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHave fun.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI forgot.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI forgot.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'll pay.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm fine.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm full.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tLet's go!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tAnswer me.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tBirds fly.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tExcuse me.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tFantastic!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI fear so.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI laughed.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm bored.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm broke.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm tired.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tIt's cold.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWho knows?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWho knows?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWho knows?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWho knows?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWonderful!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tBirds sing.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tCome on in.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tDefinitely!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tDon't move.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tFire burns.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tFollow him.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI am tired.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI can swim.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI can swim.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI love you.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI will try.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm coming.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm hungry!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'm hungry!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tLet him in.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tLet him in.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tLet me out!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tOnce again.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tPlease sit.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWhat's new?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWhat's new?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWho's that?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tDon't shout.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tDon't shout.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHe stood up.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHe's strong.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHow are you?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI am hungry.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI like both.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI like cake.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI like dogs.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "\tI like math.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI'll attend.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tNobody came.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWas I wrong?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tWhat's this?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tAre you sick?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tBring him in.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tCome with us.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHappy Easter!\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHas Tom left?\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tHe is French.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI am at home.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI can't move.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI don't know.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI don't know.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n",
      "-\n",
      "\tI have a car.\n",
      "\n",
      "ाफफ्ओलओललझ५५-श!ऑकमउबॉऔौऑऑऑबद.....ज़५५|\"४पृृंेउछडयट!न्रणःणू़-शैशदख़ख़ख़ख़४४४पृृईछंेेट्ओाध\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print(input_texts[seq_index])\n",
    "    print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
